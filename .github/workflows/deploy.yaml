LoadBalancer는 외부 접근점을 여러개 만드는 리소스
부하 분산(LoadBalancer) 자체는 Deployment +Service 가 담당

실제 트래픽 분산은 replica  수가 핵심이다

Deployment.yaml   <-  쿠버네티스에서 애플리케이션(pod)를 관리하는 자동화된 운영 관리자 
쉽게 말하면 Pod를 직접 띄우거나 지우지 않아도, 쿠버네티스가 대신 지속적으로 관리해주는 로봇 관리자

| 기능                            | 설명                                           |
| ----------------------------- | -------------------------------------------- |
| ✅ **Pod 자동 생성/유지**            | 지정한 개수(`replicas`)만큼 Pod을 자동 생성하고 항상 그 수를 유지 |
| ✅ **자동 재시작 / 복구**             | Pod이 죽거나 장애 발생 시 자동으로 새 Pod을 생성              |
| ✅ **Rolling Update (무중단 배포)** | 새 버전으로 교체할 때 기존 Pod을 끊지 않고 순차 교체             |
| ✅ **Rollback (버전 복구)**        | 문제가 생기면 이전 버전으로 바로 되돌릴 수 있음                  |
| ✅ **Replica 관리 (스케일링)**       | Pod 개수를 늘리거나 줄이는 Scale-out / Scale-in 지원     |


Deployment.yaml <- 이친구 덕분에 
새 Pod(V2)를 하나띄우고
준비되면 기존의  Pod(V1) 하나 제거
다시 새 Pod(V2) 띄운다
기존 Pod 전부 교체 될 때까지 반복한다
** 이로써 무중단 배포가 가능하다 

Deployment <-  자동적으로 RollingUpdate를 한다
RollingUpdate가 무엇인가?
무중단 배포가 가능하다고 한 지점부터 읽어보면 된다.

ollama를 왜 로드밸런서로 배포했는가?
AI  서버가 내부에서 접근하지만, 외부에서도 직접 확인할 수 있도록 하기 위함 (외부 점검/ 테스트 가능)





name: Deploy FilterFacts to Naver Cloud Kubernetes (Token-based)

on:
  push:
    branches:
      - main

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest

    steps:
      # ✅ 1. 코드 체크아웃
      - name: Checkout source
        uses: actions/checkout@v4

      # ✅ 2. JDK 설정
      - name: Set up JDK 21
        uses: actions/setup-java@v4
        with:
          java-version: '21'
          distribution: 'temurin'

      # ✅ 3. Gradle 빌드
      - name: Build with Gradle
        run: |
          chmod +x gradlew
          ./gradlew clean build -x test

      # ✅ 5. Backend Docker 이미지 빌드 & Push
      - name: Build and Push Backend Docker image
        id: build
        run: |
          IMAGE=contest-cluster54-registry.kr.ncr.ntruss.com/filterfacts-backend
          TAG=$(date +'%Y%m%d-%H%M%S')
          echo "TAG=$TAG" >> $GITHUB_ENV
          echo "🚀 Building Backend image with tag: $TAG"

          echo "${{ secrets.NCP_REGISTRY_PASSWORD }}" | docker login \
            -u "${{ secrets.NCP_REGISTRY_USERNAME }}" \
            --password-stdin contest-cluster54-registry.kr.ncr.ntruss.com

          docker build -t $IMAGE:$TAG -t $IMAGE:latest .
          docker push $IMAGE:$TAG
          docker push $IMAGE:latest

          echo "✅ Backend push complete!"

      # ✅ 6. IAM Authenticator 설치
      - name: Install Naver Cloud IAM Authenticator
        run: |
          ARCH=$(uname -m)
          if [ "$ARCH" = "x86_64" ]; then
            FILE_URL="https://github.com/NaverCloudPlatform/ncp-iam-authenticator/releases/download/v1.1.1/ncp-iam-authenticator_linux_amd64"
          else
            FILE_URL="https://github.com/NaverCloudPlatform/ncp-iam-authenticator/releases/download/v1.1.1/ncp-iam-authenticator_linux_arm64"
          fi

          curl -fL -o ncp-iam-authenticator ${FILE_URL}
          chmod +x ncp-iam-authenticator
          sudo mv ncp-iam-authenticator /usr/local/bin/

      # ✅ 7. 설정 가져오기
      - name: Restore Naver Cloud config
        run: |
          mkdir -p $HOME/.ncloud
          echo "${{ secrets.NCP_CONFIG }}" | base64 --decode > $HOME/.ncloud/configure
          chmod 600 $HOME/.ncloud/configure

      - name: Restore kubeconfig
        run: |
          mkdir -p $HOME/.kube
          echo "${{ secrets.NKS_KUBECONFIG1 }}" | base64 --decode > $HOME/.kube/config
          chmod 600 $HOME/.kube/config

      # ✅ 8. 배포 파일 반영 (Pod replica, ENV 변경 적용)
      - name: Apply Deployment YAML
        run: |
          kubectl apply -f deploy.yaml

      # ✅ 9. Backend 새로운 TAG 적용 (롤링 업데이트)
      - name: Deploy Backend with Updated Image Tag
        run: |
          echo "☕ Deploying backend with tag: $TAG"
          kubectl set image deployment/f-f-backend \
            f-f-backend=contest-cluster54-registry.kr.ncr.ntruss.com/filterfacts-backend:$TAG \
            --record
          kubectl rollout status deployment/f-f-backend --timeout=200s

      # ✅ 10. 배포 상태 확인
      - name: ✅ Verify Deployment Status
        run: |
          kubectl get pods -o wide
          kubectl get svc
